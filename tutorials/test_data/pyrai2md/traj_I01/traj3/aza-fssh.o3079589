### Starting TaskPrologue of job 3079589 on f0354 at Tue Nov 18 10:55:17 CET 2025
#   SLURM_JOB_NODELIST=f0354
#   SLURM_JOB_NUM_NODES=1
#   SLURM_NTASKS=32
#   SLURM_NPROCS=32
#   SLURM_TASKS_PER_NODE=32
#   SLURM_JOB_CPUS_PER_NODE=72
#   SLURM_EXPORT_ENV=NONE
Running on cores 0-71 with governor powersave
### Finished TaskPrologue
ERROR: Unable to locate a modulefile for 'openmpi/4.1.3-gcc11.2.0'
#0  0x1542b1c5654a in ???
#1  0x1542b1c56c0c in ???
#2  0x1542b1c87640 in ???
#3  0x154311b7fa49 in ???
#4  0x154311b7efe9 in ???
#5  0x1542c13f6737 in ???
#6  0x563610a162e4 in _PyObject_Call
	at /usr/local/src/conda/python-3.12.5/Objects/call.c:367
#7  0x5636108ecca5 in PyCFunction_Call
	at /usr/local/src/conda/python-3.12.5/Objects/call.c:387
#8  0x5636108ecca5 in _PyEval_EvalFrameDefault
	at Python/bytecodes.c:3262
#9  0x563610a9fecd in PyEval_EvalCode
	at /usr/local/src/conda/python-3.12.5/Python/ceval.c:578
#10  0x563610ac4d99 in run_eval_code_obj
	at /usr/local/src/conda/python-3.12.5/Python/pythonrun.c:1722
#11  0x563610abff4a in run_mod
	at /usr/local/src/conda/python-3.12.5/Python/pythonrun.c:1743
#12  0x563610ad8bcf in pyrun_file
	at /usr/local/src/conda/python-3.12.5/Python/pythonrun.c:1643
#13  0x563610ad820d in _PyRun_SimpleFileObject
	at /usr/local/src/conda/python-3.12.5/Python/pythonrun.c:433
#14  0x563610ad7ee3 in _PyRun_AnyFileObject
	at /usr/local/src/conda/python-3.12.5/Python/pythonrun.c:78
#15  0x563610ad0f41 in pymain_run_file_obj
	at /usr/local/src/conda/python-3.12.5/Modules/main.c:360
#16  0x563610ad0f41 in pymain_run_file
	at /usr/local/src/conda/python-3.12.5/Modules/main.c:379
#17  0x563610ad0f41 in pymain_run_python
	at /usr/local/src/conda/python-3.12.5/Modules/main.c:633
#18  0x563610ad0f41 in Py_RunMain
	at /usr/local/src/conda/python-3.12.5/Modules/main.c:713
#19  0x563610a887e6 in Py_BytesMain
	at /usr/local/src/conda/python-3.12.5/Modules/main.c:767
#20  0x154314c0d7e4 in ???
#21  0x563610a88680 in ???
#22  0xffffffffffffffff in ???
ERROR STOP See above
=== JOB_STATISTICS ===
=== current date     : Tue Nov 18 10:55:37 CET 2025
= Job-ID             : 3079589 on fritz
= Job-Name           : aza-fssh
= Job-Command        : /home/vault/bccc/bccc115h/test/pyrai2md-test/traj1/pymd.submit
= Initial workdir    : /home/vault/bccc/bccc115h/test/pyrai2md-test/traj1
= Queue/Partition    : singlenode
= Slurm account      : bccc with QOS=normal
= Requested resources:  for 01:00:00
= Elapsed runtime    : 00:00:23
= Total RAM usage    : 1.0 GiB 
= Node list          : f0354
= Subm/Elig/Start/End: 2025-11-18T10:55:12 / 2025-11-18T10:55:12 / 2025-11-18T10:55:13 / 2025-11-18T10:55:36
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/woody           221.4G  1000.0G  1500.0G        N/A     502K   5,000K   7,500K        N/A    
    /home/hpc              90.4G   104.9G   209.7G        N/A     133K     500K   1,000K        N/A    
    /home/vault           794.6G  1048.6G  2097.2G        N/A      93K     200K     400K        N/A    
    /lustre                 4.0K     0.0K     0.0K        N/A       1       80K     250K        N/A    
======================
=== Network traffic stats (does not include Infiniband) ======
= HPC internal traffic (e.g. to fileservers): 0 GB in / 0 GB out
= External traffic: 0 GB in / 0 GB out
======================
